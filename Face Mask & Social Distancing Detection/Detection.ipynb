{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da3b486",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c646a",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e9d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import mediapipe as mp\n",
    "from IPython.utils import io\n",
    "import math\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75628c92",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f675b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['WithoutMask', 'WithMask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ca49c",
   "metadata": {},
   "source": [
    "### Creating MediaPipe FaceDetection Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591af4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd18e14",
   "metadata": {},
   "source": [
    "We will be using this module for the detection of faces. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0235f3",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992317fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaskModel=tf.keras.models.load_model('MaskDetectionCORE.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086ed11",
   "metadata": {},
   "source": [
    "This model was trained on thousands of images to detect if a face is Masked or Unmasked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bda1b",
   "metadata": {},
   "source": [
    "### Initializing YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d31215",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85c5d4",
   "metadata": {},
   "source": [
    "### Defining Classes of YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0bf3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3352bc9",
   "metadata": {},
   "source": [
    "### Initializing MP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326b2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b78d85",
   "metadata": {},
   "source": [
    "### Detection from Live Video [ Webcam ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d5cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    selfie = cv2.flip(frame, 1)\n",
    "    mirror = cv2.flip(frame, 1)\n",
    "    height, width = mirror.shape[:2]\n",
    "    mirror = cv2.cvtColor(mirror, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detector.process(mirror)\n",
    "    mirror = cv2.cvtColor(mirror, cv2.COLOR_RGB2BGR)\n",
    "    if results.detections:\n",
    "        for face in results.detections:\n",
    "            bounding_box = face.location_data.relative_bounding_box\n",
    "            x = int(bounding_box.xmin * width)\n",
    "            y = int(bounding_box.ymin * height)\n",
    "            w = int(bounding_box.width * width)\n",
    "            h = int(bounding_box.height * height)\n",
    "            img = mirror[y:y+h,x:x+w]\n",
    "            try:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                break\n",
    "            threed = np.repeat(gray[...,np.newaxis], 3, -1)\n",
    "            preprocessed = preprocess_input(threed)\n",
    "            resized = cv2.resize(preprocessed, (224,224))\n",
    "            with io.capture_output() as captured:\n",
    "                predictions = MaskModel.predict(np.expand_dims(resized, axis=0))\n",
    "            accuracy = str(round(predictions.max(), 2))\n",
    "            predicted = CATEGORIES[predictions.argmax()]\n",
    "            if predicted == 'WithMask':\n",
    "                cv2.rectangle(selfie, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "                cv2.putText(selfie, 'MASKED', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            elif predicted == 'WithoutMask':\n",
    "                cv2.rectangle(selfie, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                cv2.putText(selfie, 'UNMASKED', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(mirror, 1/255, (width, height), (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layer_names)\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    for detections in layerOutputs:\n",
    "        for detection in detections:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id] \n",
    "            if confidence > 0.8 and class_id == 0:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.8, 0.5)\n",
    "    if len(indexes) > 0:\n",
    "        centroids = []\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            c = (int((x+x+w)/2), int((y+y+h)/2))\n",
    "            centroids.append(c)\n",
    "            label = 'PERSON'\n",
    "            uniqueID = str(np.where(indexes.flatten() == i)[0])[1:-1]\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            cv2.rectangle(selfie, (x,y), (x+w, y+h), (255, 0, 0), 4)\n",
    "            cv2.putText(selfie, label+\" \"+uniqueID, (x, y+30), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 3)\n",
    "        if len(centroids) > 1:\n",
    "            distmat = distance.pdist(centroids)\n",
    "            mindist = distmat[distmat.argmin()]\n",
    "            if mindist < 300:\n",
    "                cv2.putText(selfie, 'MAINTAIN SOCIAL DISTANCE', (0,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    else:\n",
    "        cv2.putText(selfie, 'NO PERSONS DETECTED', (width-400, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.imshow('Webcam', selfie)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee6989",
   "metadata": {},
   "source": [
    " ### Process given video & Save it as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49bc5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'xvid')\n",
    "out = cv2.VideoWriter('Output.mp4', fourcc, 14.0, (640, 480))\n",
    "cap = cv2.VideoCapture('VideoForDetection.mp4')\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    if _ != True:\n",
    "        break\n",
    "    selfie = cv2.flip(frame, 1)\n",
    "    mirror = cv2.flip(frame, 1)\n",
    "    height, width = mirror.shape[:2]\n",
    "    mirror = cv2.cvtColor(mirror, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detector.process(mirror)\n",
    "    mirror = cv2.cvtColor(mirror, cv2.COLOR_RGB2BGR)\n",
    "    if results.detections:\n",
    "        for face in results.detections:\n",
    "            bounding_box = face.location_data.relative_bounding_box\n",
    "            x = int(bounding_box.xmin * width)\n",
    "            y = int(bounding_box.ymin * height)\n",
    "            w = int(bounding_box.width * width)\n",
    "            h = int(bounding_box.height * height)\n",
    "            img = mirror[y:y+h,x:x+w]\n",
    "            try:\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                break\n",
    "            threed = np.repeat(gray[...,np.newaxis], 3, -1)\n",
    "            preprocessed = preprocess_input(threed)\n",
    "            resized = cv2.resize(preprocessed, (224,224))\n",
    "            with io.capture_output() as captured:\n",
    "                predictions = MaskModel.predict(np.expand_dims(resized, axis=0))\n",
    "            accuracy = str(round(predictions.max(), 2))\n",
    "            predicted = CATEGORIES[predictions.argmax()]\n",
    "            if predicted == 'WithMask':\n",
    "                cv2.rectangle(selfie, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "                cv2.putText(selfie, 'MASKED', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            elif predicted == 'WithoutMask':\n",
    "                cv2.rectangle(selfie, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                cv2.putText(selfie, 'UNMASKED', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(mirror, 1/255, (640, 480), (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layer_names)\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    for detections in layerOutputs:\n",
    "        for detection in detections:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id] \n",
    "            if confidence > 0.8 and class_id == 0:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.8, 0.5)\n",
    "    if len(indexes) > 0:\n",
    "        centroids = []\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            c = (int((x+x+w)/2), int((y+y+h)/2))\n",
    "            centroids.append(c)\n",
    "            label = 'PERSON'\n",
    "            uniqueID = str(np.where(indexes.flatten() == i)[0])[1:-1]\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            cv2.rectangle(selfie, (x,y), (x+w, y+h), (255, 0, 0), 4)\n",
    "            cv2.putText(selfie, label+\" \"+uniqueID, (x, y+30), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 3)\n",
    "        if len(centroids) > 1:\n",
    "            distmat = distance.pdist(centroids)\n",
    "            mindist = distmat[distmat.argmin()]\n",
    "            if mindist < 325:\n",
    "                cv2.putText(selfie, 'ALERT SOCIAL DISTANCE', (40,450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "    else:\n",
    "        cv2.putText(selfie, 'NO PERSONS DETECTED', (width-400, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    out.write(selfie)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1807a",
   "metadata": {},
   "source": [
    "### Capture WebCam Video For Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7e1bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting\n"
     ]
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'xvid')\n",
    "out = cv2.VideoWriter('VideoForDetection.mp4', fourcc, 20.0, (640, 480))\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    selfie = cv2.flip(frame, 1)\n",
    "    if _:\n",
    "        cv2.imshow('WEBCAM', selfie)\n",
    "        out.write(selfie)\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            print('Quitting')\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
